{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dropout, Flatten, Dense\n",
    "from keras import applications"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_data = np.load('train_cats_and_dogs_images.npz')['arr_0'].reshape([-1, 150, 150, 3])\n",
    "\n",
    "test_data = np.load('test_cats_and_dogs_images.npz')['arr_0'].reshape([-1, 150, 150, 3])\n",
    "\n",
    "train = np.zeros([2000, 150, 150, 3])\n",
    "for i in range(2000):\n",
    "    train[i] = train_data[i]\n",
    "    \n",
    "test = np.zeros([800, 150, 150, 3])\n",
    "for i in range(800):\n",
    "    test[i] = test_data[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "batch_size = 16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def save_bottleneck_features():\n",
    "    datagen = ImageDataGenerator(rescale=1./255)\n",
    "    \n",
    "    # build the VGG16 network\n",
    "    model = applications.VGG16(include_top=False, weights='imagenet')\n",
    "    \n",
    "    generator = datagen.flow(train, \n",
    "                             batch_size=batch_size,\n",
    "                             shuffle=False)\n",
    "    \n",
    "    bottleneck_features_train = model.predict_generator(generator, 2000 // batch_size)\n",
    "    np.save(open('bottleneck_features_train.npy', 'wb'), bottleneck_features_train)\n",
    "    \n",
    "    generator = datagen.flow(test, \n",
    "                             batch_size=batch_size, \n",
    "                             shuffle=False)\n",
    "    \n",
    "    bottleneck_features_validation = model.predict_generator(generator, 800 // batch_size)\n",
    "    np.save(open('bottleneck_features_validation.npy', 'wb'), bottleneck_features_validation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def train_top_model():\n",
    "    train_data = np.load(open('bottleneck_features_train.npy', 'rb'))\n",
    "    train_labels = np.array([0] * 1000 + [1] * 1000)\n",
    "    \n",
    "    test_data = np.load(open('bottleneck_features_validation.npy', 'rb'))\n",
    "    test_labels = np.array([0] * 400 + [1] * 400)\n",
    "    \n",
    "    model = Sequential()\n",
    "    model.add(Flatten(input_shape=train_data.shape[1:]))\n",
    "    model.add(Dense(256, activation='relu'))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "    \n",
    "    model.compile(loss='binary_crossentropy', \n",
    "                  optimizer='rmsprop', \n",
    "                  metrics=['accuracy'])\n",
    "    \n",
    "    model.fit(train_data,\n",
    "              train_labels, \n",
    "              epochs=50,\n",
    "              batch_size=batch_size,\n",
    "              validation_data=(test_data, test_labels))\n",
    "    model.save_weights('bottleneck_fc_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-17-76a60bea8db0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0msave_bottleneck_features\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-12-a47bac073676>\u001b[0m in \u001b[0;36msave_bottleneck_features\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m     generator = datagen.flow(train, \n\u001b[1;32m      8\u001b[0m                              \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m                              shuffle=False)\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0mbottleneck_features_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict_generator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgenerator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2000\u001b[0m \u001b[0;34m//\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/keras/preprocessing/image.py\u001b[0m in \u001b[0;36mflow\u001b[0;34m(self, x, y, batch_size, shuffle, seed, save_to_dir, save_prefix, save_format, subset)\u001b[0m\n\u001b[1;32m    547\u001b[0m             \u001b[0msave_prefix\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msave_prefix\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    548\u001b[0m             \u001b[0msave_format\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msave_format\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 549\u001b[0;31m             subset=subset)\n\u001b[0m\u001b[1;32m    550\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    551\u001b[0m     def flow_from_directory(self, directory,\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/keras/preprocessing/image.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, x, y, image_data_generator, batch_size, shuffle, seed, data_format, save_to_dir, save_prefix, save_format, subset)\u001b[0m\n\u001b[1;32m    921\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mdata_format\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    922\u001b[0m             \u001b[0mdata_format\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mK\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimage_data_format\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 923\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mK\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloatx\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    924\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;36m4\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    925\u001b[0m             raise ValueError('Input data in `NumpyArrayIterator` '\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/numpy/core/numeric.py\u001b[0m in \u001b[0;36masarray\u001b[0;34m(a, dtype, order)\u001b[0m\n\u001b[1;32m    529\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    530\u001b[0m     \"\"\"\n\u001b[0;32m--> 531\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0morder\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    532\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    533\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "save_bottleneck_features()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 2000 samples, validate on 800 samples\n",
      "Epoch 1/50\n",
      "2000/2000 [==============================] - 7s 3ms/step - loss: 0.8874 - acc: 0.7615 - val_loss: 0.2961 - val_acc: 0.8788\n",
      "Epoch 2/50\n",
      "2000/2000 [==============================] - 7s 3ms/step - loss: 0.3595 - acc: 0.8555 - val_loss: 0.2691 - val_acc: 0.8938\n",
      "Epoch 3/50\n",
      "2000/2000 [==============================] - 7s 3ms/step - loss: 0.2770 - acc: 0.8895 - val_loss: 0.3111 - val_acc: 0.8662\n",
      "Epoch 4/50\n",
      "2000/2000 [==============================] - 7s 3ms/step - loss: 0.2359 - acc: 0.9085 - val_loss: 0.3062 - val_acc: 0.8838\n",
      "Epoch 5/50\n",
      "2000/2000 [==============================] - 7s 3ms/step - loss: 0.1910 - acc: 0.9280 - val_loss: 0.3069 - val_acc: 0.8912\n",
      "Epoch 6/50\n",
      "2000/2000 [==============================] - 7s 3ms/step - loss: 0.1872 - acc: 0.9280 - val_loss: 0.4800 - val_acc: 0.8438\n",
      "Epoch 7/50\n",
      "2000/2000 [==============================] - 7s 3ms/step - loss: 0.1704 - acc: 0.9350 - val_loss: 0.2850 - val_acc: 0.9012\n",
      "Epoch 8/50\n",
      "2000/2000 [==============================] - 7s 4ms/step - loss: 0.1462 - acc: 0.9420 - val_loss: 0.3065 - val_acc: 0.9025\n",
      "Epoch 9/50\n",
      "2000/2000 [==============================] - 7s 3ms/step - loss: 0.1482 - acc: 0.9450 - val_loss: 0.3086 - val_acc: 0.9038\n",
      "Epoch 10/50\n",
      "2000/2000 [==============================] - 7s 3ms/step - loss: 0.1105 - acc: 0.9535 - val_loss: 0.4050 - val_acc: 0.8900\n",
      "Epoch 11/50\n",
      "2000/2000 [==============================] - 7s 3ms/step - loss: 0.1114 - acc: 0.9595 - val_loss: 0.4257 - val_acc: 0.8975\n",
      "Epoch 12/50\n",
      "2000/2000 [==============================] - 7s 3ms/step - loss: 0.0852 - acc: 0.9650 - val_loss: 0.6121 - val_acc: 0.8612\n",
      "Epoch 13/50\n",
      "2000/2000 [==============================] - 7s 3ms/step - loss: 0.0825 - acc: 0.9690 - val_loss: 0.4167 - val_acc: 0.8950\n",
      "Epoch 14/50\n",
      "2000/2000 [==============================] - 7s 3ms/step - loss: 0.0840 - acc: 0.9670 - val_loss: 0.4486 - val_acc: 0.8962\n",
      "Epoch 15/50\n",
      "2000/2000 [==============================] - 7s 3ms/step - loss: 0.0686 - acc: 0.9735 - val_loss: 0.5876 - val_acc: 0.8725\n",
      "Epoch 16/50\n",
      "2000/2000 [==============================] - 7s 3ms/step - loss: 0.0607 - acc: 0.9750 - val_loss: 0.4890 - val_acc: 0.9050\n",
      "Epoch 17/50\n",
      "2000/2000 [==============================] - 7s 4ms/step - loss: 0.0600 - acc: 0.9740 - val_loss: 0.5181 - val_acc: 0.8988\n",
      "Epoch 18/50\n",
      "2000/2000 [==============================] - 8s 4ms/step - loss: 0.0487 - acc: 0.9820 - val_loss: 0.5564 - val_acc: 0.9025\n",
      "Epoch 19/50\n",
      "2000/2000 [==============================] - 7s 4ms/step - loss: 0.0591 - acc: 0.9815 - val_loss: 0.5892 - val_acc: 0.9000\n",
      "Epoch 20/50\n",
      "2000/2000 [==============================] - 7s 4ms/step - loss: 0.0471 - acc: 0.9800 - val_loss: 0.5917 - val_acc: 0.8975\n",
      "Epoch 21/50\n",
      "2000/2000 [==============================] - 7s 3ms/step - loss: 0.0355 - acc: 0.9895 - val_loss: 0.5894 - val_acc: 0.8975\n",
      "Epoch 22/50\n",
      "2000/2000 [==============================] - 7s 3ms/step - loss: 0.0299 - acc: 0.9925 - val_loss: 0.6826 - val_acc: 0.8938\n",
      "Epoch 23/50\n",
      "2000/2000 [==============================] - 7s 3ms/step - loss: 0.0274 - acc: 0.9905 - val_loss: 0.6811 - val_acc: 0.8988\n",
      "Epoch 24/50\n",
      "2000/2000 [==============================] - 7s 3ms/step - loss: 0.0515 - acc: 0.9820 - val_loss: 0.6656 - val_acc: 0.9012\n",
      "Epoch 25/50\n",
      "2000/2000 [==============================] - 7s 4ms/step - loss: 0.0201 - acc: 0.9935 - val_loss: 0.6637 - val_acc: 0.9012\n",
      "Epoch 26/50\n",
      "2000/2000 [==============================] - 7s 3ms/step - loss: 0.0298 - acc: 0.9895 - val_loss: 0.7296 - val_acc: 0.8962\n",
      "Epoch 27/50\n",
      "2000/2000 [==============================] - 7s 3ms/step - loss: 0.0327 - acc: 0.9900 - val_loss: 0.6660 - val_acc: 0.8900\n",
      "Epoch 28/50\n",
      "2000/2000 [==============================] - 7s 4ms/step - loss: 0.0320 - acc: 0.9905 - val_loss: 0.7657 - val_acc: 0.8962\n",
      "Epoch 29/50\n",
      "2000/2000 [==============================] - 7s 3ms/step - loss: 0.0201 - acc: 0.9925 - val_loss: 0.8808 - val_acc: 0.8838\n",
      "Epoch 30/50\n",
      "2000/2000 [==============================] - 7s 3ms/step - loss: 0.0242 - acc: 0.9905 - val_loss: 0.6736 - val_acc: 0.8988\n",
      "Epoch 31/50\n",
      "2000/2000 [==============================] - 7s 4ms/step - loss: 0.0265 - acc: 0.9925 - val_loss: 0.7511 - val_acc: 0.9000\n",
      "Epoch 32/50\n",
      "2000/2000 [==============================] - 7s 4ms/step - loss: 0.0274 - acc: 0.9910 - val_loss: 0.9244 - val_acc: 0.8738\n",
      "Epoch 33/50\n",
      "2000/2000 [==============================] - 7s 4ms/step - loss: 0.0238 - acc: 0.9905 - val_loss: 0.7514 - val_acc: 0.8938\n",
      "Epoch 34/50\n",
      "2000/2000 [==============================] - 7s 4ms/step - loss: 0.0229 - acc: 0.9925 - val_loss: 0.8264 - val_acc: 0.8875\n",
      "Epoch 35/50\n",
      "2000/2000 [==============================] - 7s 4ms/step - loss: 0.0209 - acc: 0.9965 - val_loss: 0.8004 - val_acc: 0.8900\n",
      "Epoch 36/50\n",
      "2000/2000 [==============================] - 6s 3ms/step - loss: 0.0235 - acc: 0.9920 - val_loss: 0.7507 - val_acc: 0.9000\n",
      "Epoch 37/50\n",
      "2000/2000 [==============================] - 6s 3ms/step - loss: 0.0130 - acc: 0.9955 - val_loss: 0.8397 - val_acc: 0.9012\n",
      "Epoch 38/50\n",
      "2000/2000 [==============================] - 6s 3ms/step - loss: 0.0232 - acc: 0.9935 - val_loss: 0.7554 - val_acc: 0.8925\n",
      "Epoch 39/50\n",
      "2000/2000 [==============================] - 6s 3ms/step - loss: 0.0099 - acc: 0.9970 - val_loss: 0.8460 - val_acc: 0.8900\n",
      "Epoch 40/50\n",
      "2000/2000 [==============================] - 6s 3ms/step - loss: 0.0299 - acc: 0.9940 - val_loss: 0.7868 - val_acc: 0.9012\n",
      "Epoch 41/50\n",
      "2000/2000 [==============================] - 6s 3ms/step - loss: 0.0234 - acc: 0.9940 - val_loss: 0.8402 - val_acc: 0.8975\n",
      "Epoch 42/50\n",
      "2000/2000 [==============================] - 6s 3ms/step - loss: 0.0146 - acc: 0.9950 - val_loss: 0.8293 - val_acc: 0.8975\n",
      "Epoch 43/50\n",
      "2000/2000 [==============================] - 6s 3ms/step - loss: 0.0087 - acc: 0.9960 - val_loss: 1.1128 - val_acc: 0.8825\n",
      "Epoch 44/50\n",
      "2000/2000 [==============================] - 6s 3ms/step - loss: 0.0166 - acc: 0.9945 - val_loss: 0.8257 - val_acc: 0.9000\n",
      "Epoch 45/50\n",
      "2000/2000 [==============================] - 6s 3ms/step - loss: 0.0302 - acc: 0.9920 - val_loss: 0.8852 - val_acc: 0.8900\n",
      "Epoch 46/50\n",
      "2000/2000 [==============================] - 6s 3ms/step - loss: 0.0127 - acc: 0.9950 - val_loss: 0.9702 - val_acc: 0.8875\n",
      "Epoch 47/50\n",
      "2000/2000 [==============================] - 6s 3ms/step - loss: 0.0186 - acc: 0.9975 - val_loss: 0.8319 - val_acc: 0.9050\n",
      "Epoch 48/50\n",
      "2000/2000 [==============================] - 6s 3ms/step - loss: 0.0205 - acc: 0.9945 - val_loss: 0.8125 - val_acc: 0.9012\n",
      "Epoch 49/50\n",
      "2000/2000 [==============================] - 6s 3ms/step - loss: 0.0179 - acc: 0.9950 - val_loss: 0.8775 - val_acc: 0.8912\n",
      "Epoch 50/50\n",
      "2000/2000 [==============================] - 6s 3ms/step - loss: 0.0086 - acc: 0.9975 - val_loss: 0.8567 - val_acc: 0.9025\n"
     ]
    }
   ],
   "source": [
    "train_top_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
